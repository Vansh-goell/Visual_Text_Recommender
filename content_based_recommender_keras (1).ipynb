{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Image Recommender with Custom CNN (Keras)\n",
    "This notebook builds a CNN to extract visual features from e-commerce product images and recommends similar products based on image embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load CSV and Prepare Image Paths\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('/mnt/data/fashion.csv')\n",
    "df['ImagePath'] = df['Image'].apply(lambda x: os.path.join('images', x))\n",
    "df = df.dropna(subset=['ImageURL'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Download Images\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    image_path = os.path.join('images', row['Image'])\n",
    "    if not os.path.exists(image_path):\n",
    "        try:\n",
    "            r = requests.get(row['ImageURL'], timeout=5)\n",
    "            with open(image_path, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        except:\n",
    "            print(f\"Failed to download {row['ImageURL']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Image Preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory='images',\n",
    "    x_col='Image',\n",
    "    y_col='Category',\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory='images',\n",
    "    x_col='Image',\n",
    "    y_col='Category',\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build Custom CNN Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu', name='embedding'),\n",
    "    Dense(train_gen.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train Model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Extract Embeddings\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "feature_model = Model(inputs=model.input, outputs=model.get_layer('embedding').output)\n",
    "\n",
    "embeddings = []\n",
    "for img_path in tqdm(df['ImagePath']):\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(128, 128))\n",
    "        img_array = image.img_to_array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        embedding = feature_model.predict(img_array, verbose=0)[0]\n",
    "        embeddings.append(embedding)\n",
    "    except:\n",
    "        embeddings.append(np.zeros(128))\n",
    "\n",
    "df['embedding'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f16857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Recommend Similar Products using Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Convert list of embeddings to numpy array\n",
    "embedding_matrix = np.array(df['embedding'].tolist())\n",
    "\n",
    "# Function to get top N similar products\n",
    "def get_similar_products(product_id, top_n=5):\n",
    "    idx = df[df['ProductId'] == product_id].index[0]\n",
    "    query_vec = embedding_matrix[idx].reshape(1, -1)\n",
    "    similarities = cosine_similarity(query_vec, embedding_matrix)[0]\n",
    "    similar_indices = similarities.argsort()[::-1][1:top_n+1]\n",
    "    return df.iloc[similar_indices][['ProductId', 'ProductTitle', 'Category', 'ImagePath']]\n",
    "\n",
    "# Example: get 5 products similar to ProductId 42419\n",
    "get_similar_products(42419)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
